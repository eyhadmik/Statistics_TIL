## 분류 모델 평가하기
- 정확도(accuracy) : 정확히 분류된 비율
- 혼동행렬(confusion matrix) : 분류에서 예측된 결과와 실제 결과에 대한 레코드의 개수를 표시한 테이블
- 민감도(sensitivity) : 정확히 분류된 1의 비율
- 특이도(specificity) : 정확히 분류된 0의 비율
- 정밀도(precision) : 정확히 1이라고 예측된 1의 비율
- ROC 곡선(ROC curve) : 민감도와 특이성을 표시한 그림
- 리프트(lift) : 모델이 다른 확률 컷오프에 대해(비교적 드문) 1을 얼마나 더 효과적으로 구분하는지 나타내는 측정 지표

## K-nearest neighbors(KNN)
1. 특징들이 가장 유사한(즉, 예측변수들이 유사한) K개의 레코드를 찾는다.
2. 분류 : 이 유사한 레코드들 중에 다수가 속한 클래스가 무엇인지 찾은 후에 새로운 레코드를 그 클래스에 할당한다.
3. 예측(KNN regression) : 유사한 레코드들의 평균을 찾아서 새로운 레코드에 대한 예측값으로 사용한다.
- 이웃(neighbor) : 예측변수에서 값들이 유사한 레코드
- 거리지표(distance metric) : 각 레코드 사이가 얼마나 멀리 떨어져 있는지를 나타내는 단일 값
- 표준화(standardization) : 평균을 뺀 후에 표준편차로 나누는 일
- z 점수(z-score) : 표준화를 통해 얻은 값
- K : 최근접 이웃을 계산하는 데 사용되는 이웃의 갯수
- KNN은 가장 간단한 예측/분류 방법 중 하나이다.
- 회귀와는 달리 모델을 피팅하는 과정이 필요 없다.
- 특징들이 어떤 척도에 존재하는지, 가까운 정도를 어떻게 측정할 것인지, K를 어떻게 설정한 것인지에 따라 예측 결과가 달라진다.
- 모든 예측변수들은 수치형이어야 한다.
- K를 잘 선택하는 것은 KNN의 성능을 결정하는 아주 중요한 요소이다.
- 일반적으로 K가 너무 작으면 데이터의 노이즈 성분까지 고려하는 오버피팅 문제가 발생한다.
- K 값이 클수록 결정 함수를 좀 더 부드럽게 하는 효과를 가져와 학습 데이터에서의 오버피팅 위험을 낮출 수 있다.
- 반대로 K를 너무 크게 하면 결정 함수가 너무 과하게 평탄화되어(오버스무딩) 데이터의 지역 정보를 예측하는 KNN의 기능을 잃어버리게 된다.
- 오버피팅과 오버스무딩 사이의 균형을 맞춘 최적의 K 값을 찾기 위해 정확도 지표들을 활용한다.
- 홀드아웃 데이터 또는 타당성 검사를 위해 따로 떼어놓은 데이터에서의 정확도를 가지고 K 값을 결정하는데 사용한다.
- 최적의 K를 결정하는 일반적인 규칙은 없다. 데이터에 따라 크게 달라진다.
- 데이터에 노이즈가 거의 없고 아주 잘 구조화된 데이터의 경우 K 값이 작을수록 잘 동작한다.